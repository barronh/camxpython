{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Modify a Selected Source\n\nPoint sources may be facilities or individual stacks. This example demonstrates\nhow to apply a scaling factor to all sources in some region. The region can be\nas simple as a rectangular box, a circle, or any geographic shape you can\ndefine.\n\nThe basic steps are:\n\n1. Copy an existing emissions file.\n2. Define an area within which to apply emissions sclaing.\n3. Define a multiplicative scaling factor\n4. Apply the scaling factor to all cells within the area.\n5. Make a plot demonstrating the change.\n\n*Reminder*: You must have already activated your python environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\nFind a source in the in \"Online 2020 NEI Data Retrieval Tool\"\nhttps://www.epa.gov/air-emissions-inventories/2020-national-emissions-inventory-nei-data\n- As an example, I chose single stack with the largest NO rate; then updated\n  the lon/lat to the nearest source in the NEI 2020 inventory\n- You'll have a chance to adjust your shape until you capture the intended source.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# date to process\ndate = '20160610'\n# file to copy\noldpath = f'../../camx/ptsrce/point.camx.ptnonipm.{date}.nc'\n# new file to create\nnewpath = f'outputs/point.camx.ptnonipm_edit.{date}.nc'\n# figure demonstrating change\nfigpath = 'outputs/example_ptsrce_scaleregion.png'\n\n# Region to modify\nshape = 'box'  # box, circle, or custom\ncenter = (-82.5436, 36.5224)  \ndx = 250  # m (used as radius for circle)\ndy = 250  # m (ignored for circle)\n\n\n# factor to apply within the shape\nscalekeys = ['NO', 'NO2', 'HONO']  # a list of species or 'all'\nfactor = 1.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Folders\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport netCDF4\nimport pyproj\nimport shutil\nfrom shapely import points, box\nimport os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Output and Remove if it exists\n- Use an existing file as a template\n- Create a copy for direct modification\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "os.makedirs('outputs', exist_ok=True)\nif os.path.exists(newpath):\n    os.remove(newpath)\n\nshutil.copyfile(oldpath, newpath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Open Files\n- Open the existing file in read-only mode\n- Open the new file in append mode\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "oldf = netCDF4.Dataset(oldpath, mode='r')\nnewf = netCDF4.Dataset(newpath, mode='a')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select Emission Variables to Scale\nIf scalekeys is all, select all emission variables by units\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if scalekeys == 'all':\n    scalekeys = [\n        k for k, v in newf.variables.items()\n        if v.units.strip() in ('mol hr-1', 'g hr-1')\n    ]\n\nnoscalekeys = sorted(set(newf.variables).difference(scalekeys))\nprint('INFO:: no scale', noscalekeys)\nprint('INFO:: to scale', scalekeys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define relevant sources\n- Create a projection\n- Define an area to scale in\n    - in a rectangle,\n    - in a circle, or\n    - within a complex custom shape\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "attrs = {k: oldf.getncattr(k) for k in oldf.ncattrs()}\nproj4tmpl = '+proj=lcc +lat_0={YCENT} +lon_0={P_GAM}'\nproj4tmpl += ' +lat_1={P_ALP} +lat_2={P_BET} +R=6370000 +units=m +no_defs'\nproj4str = proj4tmpl.format(**attrs)\nproj = pyproj.Proj(proj4str)\n\ncx, cy = proj(*center)                               # project to x/y\nif shape == 'box':\n    myshp = box(cx - dx, cy - dy, cx + dx, cy + dy)  # - define a rectangle\nelif shape == 'circle':\n    myshp = points(cx, cy).buffer(dx)                # - define a circle\nelif shape == 'custom':\n    # define some custom shape based on a shapefile\n    import geopandas as gpd\n    # downloaded from census.gov\n    cntypath = '../../www2.census.gov/geo/tiger/TIGER2020/COUNTY/tl_2020_us_county.zip'\n    # Read just in the continental US\n    cnty = gpd.read_file(cntypath, bbox=(-135, 20, -60, 60))\n\n    # Select counties in Georgia, reproject to grid space, collapse to one big shape (i.e, state)\n    # myshp = cnty.query('STATEFP == \"13\"').to_crs(proj.srs).union_all()\n\n    # Select DeKalb county in Georgia, reproject to grid space, collapse to one shape\n    myshp = cnty.query('GEOID == \"13091\"').to_crs(proj.srs).union_all()\nelse:\n    raise KeyError(f'For shape, got {shape} -- use box or circle')\n\npsxy = points(oldf['xcoord'][:], oldf['ycoord'])  # make points for each source\nismine = myshp.intersects(psxy)                   # find all points in shape\nprint(f'INFO:: {ismine.sum()} point sources in myshp')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Point Source Distances\n- Group stacks by unique distance from myshp perimeter.\n- Report all clusters within maxdist.\n   - Check that the number inside (0m) matches your expectation.\n   - Check for nearby clusters that might be the same facilty.\n   - Consider adjusting dx, dy or shape type to better capture the source.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "maxdist = 10e3  # stop looking at 10km\npsdist = points(cx, cy).distance(psxy)\nfdists, fcnts = np.unique(psdist, return_counts=True)\nprint('INFO:: Stacks by distance from myshp center')\nfor fdist, fcnt in zip(fdists, fcnts):\n    print(f'INFO:: {fdist:6.0f}m: {fcnt}')\n    if fdist > maxdist:\n        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply Scaling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for skey in scalekeys:\n    print(f'INFO:: multiplying {skey} by {factor:.1%} at selected point sources')\n    newvals = oldf[skey][:].copy()\n    newvals[:, ismine] *= factor\n    newf[skey][:] = newvals\n\nnewf.sync()\ndel newf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Source to confirm operational\n- Create gridded data for quick visualiation\n- Show new, original and difference.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.colors as mc\nimport matplotlib.pyplot as plt\nimport pycno\nimport numpy as np\n\noldf = netCDF4.Dataset(oldpath, mode='r')\nnewf = netCDF4.Dataset(newpath, mode='r')\n\nx = oldf['xcoord'][:]\ny = oldf['ycoord'][:]\n# add all emission keys\nzold = sum([oldf[ek][:].mean(0) for ek in scalekeys])\nznew = sum([newf[ek][:].mean(0) for ek in scalekeys])\n\nxedges = np.arange(0.5, oldf.NCOLS) * oldf.XCELL + oldf.XORIG\nyedges = np.arange(0.5, oldf.NROWS) * oldf.YCELL + oldf.YORIG\nHold, _, _ = np.histogram2d(y, x, weights=zold, bins=[yedges, xedges])\nHnew, _, _ = np.histogram2d(y, x, weights=znew, bins=[yedges, xedges])\n\ngskw = dict(left=0.333, right=0.967)\nfig, axx = plt.subplots(1, 3, figsize=(16, 4))\nopts = dict(norm=mc.LogNorm(10), cmap='viridis')\nqm = axx[0].pcolormesh(xedges, yedges, Hold, **opts)\nfig.colorbar(qm, label='Old NOx [mol hr-1]')\naxx[0].set(title=f'Old NO sum={Hold.sum() / 1e3:.0f}kmol/h')\nqm = axx[1].pcolormesh(xedges, yedges, Hnew, **opts)\nfig.colorbar(qm, label='New NOx [mol hr-1]')\naxx[1].set(title=f'New NO sum={Hnew.sum() / 1e3:.0f}kmol/h')\nopts['norm'] = mc.TwoSlopeNorm(0)\nopts['cmap'] = 'seismic'\nqm = axx[2].pcolormesh(xedges, yedges, Hnew - Hold, **opts)\nfig.colorbar(qm, label='New - Old NOx [mol hr-1]')\naxx[2].set(title=f'Diff NO sum={(Hnew.sum() - Hold.sum()) / 1e3:.0f}kmol/h')\npycno.cno(proj=proj).drawstates(resnum=1, ax=axx)\n\nfig.savefig(figpath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extra Credit\n1. Modify the custom section to scale all point sources in your home state.\n2. Modify the custom section to scale all point sources in the counties in a nonattainment area.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}